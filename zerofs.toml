# ZeroFS Configuration File
# Generated by ZeroFS v1.0.1
#
# ============================================================================
# ENVIRONMENT VARIABLE SUBSTITUTION
# ============================================================================
# This config file supports environment variable substitution.
# 
# Supported syntax:
#   - ${VAR} or $VAR  : Environment variable substitution
# 
# Examples:
#   encryption_password = "${ZEROFS_PASSWORD}"
#   dir = "${HOME}/.cache/zerofs"
#   access_key_id = "${AWS_ACCESS_KEY_ID}"
#
# All referenced environment variables must be set, or the config will fail to load.
#
# ============================================================================
# SERVER CONFIGURATION
# ============================================================================
# - To disable a server, remove or comment out its entire section
# - Unix sockets are optional for 9P and NBD servers
# - NFS only supports TCP connections
# - Each protocol supports multiple bind addresses
# 
# Examples:
#   addresses = ["127.0.0.1:2049"]                  # IPv4 localhost only
#   addresses = ["0.0.0.0:2049"]                    # All IPv4 interfaces
#   addresses = ["[::]:2049"]                       # All IPv6 interfaces
#   addresses = ["127.0.0.1:2049", "[::1]:2049"]  # Both IPv4 and IPv6 localhost
#
# ============================================================================
# CLOUD STORAGE
# ============================================================================
# - For S3: Configure [aws] section with your credentials
# - For Azure: Configure [azure] section with your credentials
# - For GCS: Configure [gcp] section or set GOOGLE_APPLICATION_CREDENTIALS env var
# - For local storage: Use file:// URLs (no cloud config needed)
# ============================================================================

[cache]
dir = "${HOME}/.cache/zerofs"
disk_size_gb = 10.0
memory_size_gb = 1.0

[storage]
url = "s3://my-bucket/zerofs-data"
encryption_password = "testing123"

[servers.nfs]
addresses = ["127.0.0.1:2049"]

[servers.ninep]
addresses = ["127.0.0.1:5564"]
unix_socket = "/tmp/zerofs.9p.sock"

[servers.nbd]
addresses = ["127.0.0.1:10809"]
unix_socket = "/tmp/zerofs.nbd.sock"

[servers.rpc]
addresses = ["127.0.0.1:7000"]
unix_socket = "/tmp/zerofs.rpc.sock"

[aws]
access_key_id = "minioadmin"
secret_access_key = "minioadmin123"
endpoint = "http://localhost:9000"
allow_http = "true"

# Optional AWS S3 settings (uncomment to use):
# endpoint = "https://s3.us-east-1.amazonaws.com"  # For S3-compatible services
# default_region = "us-east-1"
# allow_http = "true"  # For non-HTTPS endpoints

# Optional filesystem configuration
# Limit the maximum size of the filesystem to prevent unlimited growth
# If not specified, defaults to 16 EiB (effectively unlimited)
#
# Compression algorithm for chunk data:
#   - "lz4" (default): Fast compression, moderate ratio
#   - "zstd-{level}": Configurable compression (level 1-22)
#     Level 1 is fastest, level 22 is maximum compression
#     Recommended for zstd: zstd-3 for balanced speed/compression
#
# Note: Compression can be changed at any time. Existing data remains
# readable regardless of compression setting (auto-detected on read).

# [filesystem]
# max_size_gb = 100.0   # Limit filesystem to 100 GB
# compression = "lz4"  # or "zstd-3", "zstd-19", etc.

# Optional LSM tree tuning parameters
# Advanced performance tuning for the underlying LSM tree storage engine
# Only modify these if you understand LSM tree behavior

# [lsm]
# l0_max_ssts = 16                 # Max SST files in L0 before compaction (default: 16, min: 4)
# max_unflushed_gb = 1.0           # Max unflushed data before forcing flush in GB (default: 1.0, min: 0.1)
# max_concurrent_compactions = 8   # Max concurrent compaction operations (default: 8, min: 1)
# flush_interval_secs = 30         # Interval between periodic flushes in seconds (default: 30, min: 5)

# Optional Azure settings can be added to [azure] section

# [azure]
# storage_account_name = "${AZURE_STORAGE_ACCOUNT_NAME}"
# storage_account_key = "${AZURE_STORAGE_ACCOUNT_KEY}"

# Optional GCS (Google Cloud Storage) settings
# Use gs:// URLs with the [gcp] section

# [gcp]
# service_account = "${GCS_SERVICE_ACCOUNT}"  # Path to service account JSON file
# Or use application_credentials = "${GOOGLE_APPLICATION_CREDENTIALS}"
